{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MA-MOROB-M02: Trajectory Estimation (Semester 1)\n",
    "\n",
    "*part of the Programme \"Mobile Robotics\" (M.Sc.) at Bonn University*\n",
    "\n",
    "## Methods for high precision trajectory estimation of mobile mapping vehicles on crop fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Need for High Precision Trajectory Estimation (in Agricultural Mapping)\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"./assets/trajectory-need-illustration.svg\" width=\"40%\"/>\n",
    "</div>\n",
    "\n",
    "- **Positional Accuracy**: Even small deviations from planned trajectories can lead to significant consequences:\n",
    "  - **Overlapping treatment**: Wasting resources (fertilizer, pesticides, seeds)\n",
    "  - **Missed areas**: Reducing yield and creating uneven crop development\n",
    "  - **Crop damage**: Physical damage from vehicles moving off designated paths\n",
    "\n",
    "- **Mapping Quality**: Poor trajectory estimation directly impacts the quality of collected data, affecting:\n",
    "  - Precise crop monitoring (e.g. tracking individual crops over time)\n",
    "  - Accurate field mapping\n",
    "  - Reliable yield prediction models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Concrete Problem Introduction\n",
    "\n",
    "<!--\n",
    "* Add robot data recording video here\n",
    "* explain to want to come back multiple times, monitor crop growth\n",
    "* introduce the problem of robot localisation\n",
    "* ask about other scenarios where precision localisation is needed\n",
    "* explain the simplicity of a row (1D) in the strawberry tunnel case\n",
    "-->\n",
    "\n",
    "<div align=\"middle\">\n",
    "<video width=\"80%\" controls autoplay loop muted>\n",
    "      <source src=\"assets/thorvald-data.mp4\" type=\"video/mp4\">\n",
    "</video></div>\n",
    "\n",
    "<center>An Example of Crop Monitoring with a Mobile Robot</center>\n",
    "\n",
    "**Strawberry Producer: \"I want to monitor the growth of my individual strawberry plants, identifying underperforming ones\"**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Crop Monitoring Robot\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td width=\"40%\">\n",
    "            <img src=\"./assets/thorvald-cameras.jpg\" width=\"100%\"/>\n",
    "        </td>\n",
    "        <td>\n",
    "\n",
    "### Robot Specifications\n",
    "* 4 wheel drive, 4 wheel steering\n",
    "* Multiple Cameras, including Hyperspectral\n",
    "* LiDAR\n",
    "* GPS\n",
    "* IMU\n",
    "* Odometry\n",
    "\n",
    "### Task\n",
    "* Monitor crop growth\n",
    "* Identify underperforming plants\n",
    "* Create yield prediction models\n",
    "* Disease detection (powdery mildew)\n",
    "\n",
    "</td></tr></table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Module \"Trajectory Estimation\" -- Learning Objectives\n",
    "\n",
    "1. **Understand and Apply**: Demonstrate a comprehensive understanding of theoretical principles underlying trajectory estimation, including coordinate systems, sensor models, and state estimation techniques.\n",
    "2. **Analyse and Evaluate**: Critically analyse various trajectory estimation methods and evaluate their suitability for different environments and applications.\n",
    "3. **Design and Implement**: Design and implement appropriate sensor fusion algorithms for accurate trajectory estimation in challenging environments.\n",
    "4. **Evaluate Performance**: Assess the performance of trajectory estimation systems using appropriate metrics and validation techniques.\n",
    "5. **Problem Solve**: Develop solutions for trajectory estimation in environments with specific challenges, such as GPS-denied areas, dynamic obstacles, or varying terrain.\n",
    "6. **Research and Innovate**: Demonstrate awareness of current research trends and innovations in trajectory estimation for mobile sensing platforms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Draft Module Syllabus\n",
    "\n",
    "### Fundamentals of Trajectory Estimation and Problem Introduction\n",
    "- Coordinate systems and transformations (global vs. local)\n",
    "- Introduction to state representation and rigid body kinematics\n",
    "- Applications and challenges in trajectory estimation (example Crop Monitoring and Precision Agriculture)\n",
    "- Precision vs. accuracy in different application domains\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Global Localisation for Trajectory Estimation\n",
    "- GNSS/GPS principles and error sources\n",
    "- RTK and PPK techniques for high-precision positioning\n",
    "- GNSS limitations in various environments\n",
    "\n",
    "### Local Sensors for Trajectory Estimation\n",
    "- Interoception: \n",
    "  - Inertial Measurement Units (IMUs): principles and types\n",
    "  - Odometry sensors (wheel encoders, visual odometry)\n",
    "- Exteroception: Environmental sensors (LiDAR, cameras, radar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### Sensor Fusion & Estimation Theory\n",
    "- Probabilistic state estimation fundamentals\n",
    "- Kalman filtering: theory and implementation\n",
    "- Kalman Filter variants (EKF, UKF)\n",
    "- Particle filters and Monte Carlo methods\n",
    "- Smoothing techniques vs. filtering techniques\n",
    "\n",
    "### Multi-Sensor Calibration\n",
    "- Calibration of sensor arrays\n",
    "- Online calibration techniques\n",
    "- Sensor degradation detection and handling\n",
    "- Quality metrics and validation approaches\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Advanced Topics in Trajectory Estimation\n",
    "- Deep learning approaches for state estimation\n",
    "- Place recognition and loop closure techniques\n",
    "- Long-term autonomy \n",
    "- Distributed (multi-agent) trajectory estimation\n",
    "\n",
    "### Real World Applications and Limitations\n",
    "- Real-time implementation considerations and computational complexity\n",
    "- Methods for GPS-denied environments\n",
    "- Dynamic (slow and fast) changing environments\n",
    "- Example Applications\n",
    "    - Infrastructure inspection\n",
    "    - Autonomous agricultural vehicles and precision farming\n",
    "    - Indoor mobile robots and warehouse automation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Assessment\n",
    "\n",
    "* Oral Examination 50%\n",
    "    - 20 minutes oral examination on the theoretical principles of trajectory estimation\n",
    "    - indicative topics: coordinate systems, sensor models, state estimation techniques, sensor fusion, calibration, and validation\n",
    "* Coursework, 50%\n",
    "    - Handling different real-world sensor data sets (IMU, LiDAR, camera, GPS)\n",
    "    - Implementing a selection of trajectory estimation algorithms\n",
    "    - Comparative scientific evaluation of their performance\n",
    "    - Implementing a trajectory estimation system in ROS2 (simulation in devcontainer)\n",
    "    - Presentation of results and discussion of findings (assessed)\n",
    "<div align=\"middle\">\n",
    "<img width=\"40%\" src=\"./assets/gazebo.png\">\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Foundations: Mathematical Representation of a 3D Trajectory\n",
    "\n",
    "**A robot trajectory refers to the path that a rigid body (robot) follows through space over time**\n",
    "\n",
    "\n",
    "**Includes both the position and orientation**\n",
    "\n",
    "\n",
    "<div align=\"middle\">\n",
    "<img width=\"80%\" src=\"./assets/trajectory-illustration.svg\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Special Euclidean Group SE(3)\n",
    "\n",
    "The most comprehensive representation of any rigid body trajectory is through the Special Euclidean Group in 3 dimensions, denoted as $SE(3)$. \n",
    "\n",
    "This representation captures both the position (translation) and orientation (rotation) of a rigid body in 3D space.\n",
    "\n",
    "Mathematically, SE(3) can be represented as a 4×4 matrix:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix} \n",
    "R & \\vec{t} \\\\\n",
    "0 & 1 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $R$ is a 3×3 rotation matrix that belongs to the Special Orthogonal Group SO(3)\n",
    "- $\\vec{t}$ is a 3×1 translation vector\n",
    "- The bottom row [0 0 0 1] completes the homogeneous transformation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Some Properties of the Special Euclidean Group SE(3)\n",
    "\n",
    "- **Rigid Body Transformations**: SE(3) represents all possible rigid body transformations (rotations and translations) in 3D space\n",
    "  \n",
    "- **Structure**:\n",
    "  - 6 degrees of freedom (3 for rotation, 3 for translation)\n",
    "  \n",
    "- **Key Properties**:\n",
    "  - **Group Structure**: Closed under composition (combining two transformations yields another valid transformation)\n",
    "  - **Invertibility**: Every transformation has an inverse\n",
    "  - **Non-commutativity**: Order matters ($T_1 \\cdot T_2 \\neq T_2 \\cdot T_1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Relevance for Robotics more generally\n",
    "\n",
    "* This representation allows us to transform points from one coordinate frame to another\n",
    "* In Robotics often need to relate positions between different reference frames (e.g., robot base frame, world frame, end-effector frame)\n",
    "    * trajectory estimation\n",
    "    * calibration\n",
    "\n",
    "<img src=\"./assets/frames.svg\" width=\"100%\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Time Parameterisation\n",
    "\n",
    "A complete trajectory representation includes time as a parameter. This can be written as:\n",
    "\n",
    "$$T(t) \\in SE(3)$$\n",
    "\n",
    "Where $T(t)$ represents the pose (position and orientation) of the robot at time $t$.\n",
    "\n",
    "In practical robotics applications, trajectories are often represented as:\n",
    "\n",
    "1. **Discrete Waypoints**: A sequence of poses $(T_1, T_2, ..., T_n)$ that the robot should pass through at specific times $(t_1, t_2, ..., t_n)$.\n",
    "2. **Parametric Curves**: Such as splines or polynomials that smoothly interpolate between waypoints.\n",
    "3. **Joint Space Trajectories**: For robot manipulators, trajectories are often represented in joint space rather than Cartesian space, as a time-varying vector of joint angles $θ(t)$.\n",
    "\n",
    "<div align=\"middle\">\n",
    "<img width=\"40%\" src=\"./assets/trajectory-illustration.svg\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "## in 2D\n",
    "\n",
    "### Special Euclidean Group SE(2)\n",
    "\n",
    "* Captures both position and orientation in a plane.\n",
    "* SE(2) can be represented as a 3×3 matrix of the form:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix} \n",
    "\\cos(\\theta) & -\\sin(\\theta) & t_x \\\\\n",
    "\\sin(\\theta) & \\cos(\\theta) & t_y \\\\\n",
    "0 & 0 & 1 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- The 2×2 rotation matrix in the upper-left represents rotation by angle θ in the plane\n",
    "- $(t_x, t_y)$ is the 2D translation vector\n",
    "- The bottom row [0 0 1] completes the homogeneous transformation\n",
    "\n",
    "\n",
    "A minimal representation using $(x, y, \\theta)$ where $(x, y)$ is the position and $\\theta$ is the orientation angle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "### Specific 2D Applications\n",
    "\n",
    "Several specialized representations appear in 2D robotics:\n",
    "\n",
    "1. **Differential drive robots**: Trajectories expressed in terms of left and right wheel velocities $(v_L, v_R)$ or linear and angular velocities $(v, \\omega)$\n",
    "2. **Ackermann steering** (car-like robots): Trajectories parameterized by speed and steering angle\n",
    "3. **Holonomic robots**: Trajectories specified by velocity vectors that can point in any direction independent of orientation\n",
    "\n",
    "### Practical Example\n",
    "\n",
    "For a simple differential drive robot following a 2D trajectory, we might represent the robot's state at time $t$ as:\n",
    "\n",
    "$$s(t) = (x(t), y(t), \\theta(t))$$\n",
    "\n",
    "With the kinematic model:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\dot{x}(t) &= v(t) \\cos(\\theta(t)) \\\\\n",
    "\\dot{y}(t) &= v(t) \\sin(\\theta(t)) \\\\\n",
    "\\dot{\\theta}(t) &= \\omega(t)\n",
    "\\end{align}$$\n",
    "\n",
    "Where $v(t)$ is the linear velocity and $\\omega(t)$ is the angular velocity at time $t$.\n",
    "\n",
    "The 2D representation is not only simpler computationally but is also sufficient for many practical robotics applications, including most ground robots, autonomous vehicles, and planar manipulators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Trajectory Estimation as a State Estimation Problem\n",
    "\n",
    "### Classes of Probabilistic Sequential Models:\n",
    "\n",
    "Probabilistic Graphical Models with *Hidden States*, estimated from *Observations*:\n",
    "\n",
    "<div align=\"middle\">\n",
    "<img src=\"./assets/pgm-models.svg\" alt=\"pgm\" width=\"50%\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Current state estimation based on past states and observations\n",
    "   - **Filtering** algorithms such as:\n",
    "     - Kalman filter (for linear Gaussian systems)\n",
    "     - Extended Kalman filter (for nonlinear systems, robots)\n",
    "     - Unscented Kalman filter (for highly nonlinear systems)\n",
    "     - Particle filter (for general non-Gaussian, nonlinear systems)\n",
    "   - These algorithms compute $P(x_t | y_{1:t})$ - the probability of the current state $x_t$ given all observations $y_{1:t}$ up to now ($t$)\n",
    "\n",
    "<!--\n",
    "**Next state prediction**:\n",
    "   - **Prediction** algorithms including:\n",
    "     - Predictive step in Kalman filtering\n",
    "     - Forward models in dynamic Bayesian networks\n",
    "     - State transition models in hidden Markov models\n",
    "     - Forecast models in time series analysis\n",
    "   - These compute $P(x_{t+1} | y_{1:t})$ - predicting the next state given observations up to now\n",
    "\n",
    "\n",
    "3. **Most likely sequence of states from observation sequence**:\n",
    "   - **Smoothing** and **decoding** algorithms such as:\n",
    "     - Viterbi algorithm (for finding the most probable state sequence)\n",
    "     - Forward-backward algorithm (for computing marginal distributions)\n",
    "     - Rauch-Tung-Striebel smoother (for linear Gaussian systems)\n",
    "   - These compute \n",
    "        $$arg max_{x_{1:T}} P(x_{1:T} | y_{1:T})$$\n",
    "     i.e. the most likely complete state trajectory given all observations\n",
    "\n",
    "All of these tasks can be formulated within the framework of dynamic Bayesian networks, which are temporal extensions of probabilistic graphical models that explicitly represent the evolution of random variables over time.\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Principles of the Kalman Filter\n",
    "\n",
    "\n",
    "The Kalman filter manages to incorporate all past measurements implicitly through recursion.\n",
    "\n",
    "1. **State representation**: The Kalman filter maintains a sufficient statistic of all past information in the form of:\n",
    "   - A state estimate (mean vector)\n",
    "   - A covariance matrix (representing uncertainty)\n",
    "\n",
    "2. **Recursive nature**: The current state estimate already contains information from all previous measurements because:\n",
    "   - At each step t, the state estimate x̂(t|t) is based on x̂(t-1|t-1) and y(t)\n",
    "   - But x̂(t-1|t-1) was itself based on x̂(t-2|t-2) and y(t-1)\n",
    "   - And so on, all the way back to the initial state\n",
    "\n",
    "3. **Markov property**: The Kalman filter exploits the Markov property of the system - the current state contains all the information needed to predict future states, so we don't need to store the entire history.\n",
    "\n",
    "4. **Optimal property**: For linear Gaussian systems, this recursive estimation is provably optimal - the state estimate and covariance at time t are sufficient statistics for all measurements up to time t.\n",
    "\n",
    "So while the Kalman filter equations only explicitly reference the previous state estimate and current observation:\n",
    "\n",
    "```\n",
    "Predict:\n",
    "x̂(t|t-1) = F·x̂(t-1|t-1)\n",
    "P(t|t-1) = F·P(t-1|t-1)·F' + Q\n",
    "\n",
    "Update:\n",
    "K(t) = P(t|t-1)·H'·[H·P(t|t-1)·H' + R]^(-1)\n",
    "x̂(t|t) = x̂(t|t-1) + K(t)·[y(t) - H·x̂(t|t-1)]\n",
    "P(t|t) = [I - K(t)·H]·P(t|t-1)\n",
    "```\n",
    "\n",
    "It's actually integrating information from all past measurements through this recursive structure. This is one of the elegant properties of the Kalman filter - it provides a compact, computationally efficient way to incorporate the entire measurement history without having to store or reprocess that history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
